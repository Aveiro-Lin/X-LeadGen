{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e482d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mvclab-gpuserver-57        \u001b[m  Sun Mar 10 16:36:41 2024  \u001b[1m\u001b[30m515.65.01\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 30'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1124\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myuzhenqin\u001b[m(\u001b[33m813M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 51'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m16760\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3847M\u001b[m) \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3257M\u001b[m) \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3105M\u001b[m) \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3119M\u001b[m) \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3121M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2270\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myuzhenqin\u001b[m(\u001b[33m1959M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 4180\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myuzhenqin\u001b[m(\u001b[33m3869M\u001b[m)\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 37'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 5393\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m1957M\u001b[m) \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3125M\u001b[m)\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 55'C\u001b[m, \u001b[32m 16 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6929\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3309M\u001b[m) \u001b[1m\u001b[30myangli\u001b[m(\u001b[33m3309M\u001b[m)\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  311\u001b[m / \u001b[33m24576\u001b[m MB |\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2476\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mrobotics\u001b[m(\u001b[33m2165M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20890acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在之前的蒸馏基线上，加入ABCHLN单导联的GAN，生成4倍的数据，在ABCHLN验证，在TR进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c75baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DG_models import generate_model\n",
    "from datasets import train_loader,val_loader,test_loader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] ='4'\n",
    "device='cuda:0'\n",
    "import wfdb\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import sklearn.metrics\n",
    "import csv\n",
    "import copy\n",
    "from utils import *\n",
    "import torch.nn.functional as F  \n",
    "from collections import deque  \n",
    "import random\n",
    "\n",
    "\n",
    "import sys\n",
    "import ast\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import wfdb\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from scipy import signal\n",
    "import torch.nn.init as init\n",
    "from collections import deque  \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from collections import defaultdict\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import functional as F\n",
    "from models.DG_models import generate_model\n",
    "from datasets import train_loader,val_loader,test_loader\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7840988",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr=2e-3\n",
    "gan_aug=3\n",
    "batch_size=128\n",
    "max_lr=base_lr*batch_size/256\n",
    "min_lr=max_lr/100\n",
    "distill=True\n",
    "DG_method_student='DG_GR'\n",
    "DG_method_teacher='teacher_self_distill_leadI_GRL'\n",
    "GRL_loss_beta=0.05\n",
    "DGGR_smooth_eps=0.3\n",
    "ts_label_beta=0.3\n",
    "ts_feature_beta=0.3\n",
    "train_val_test_split=[0.8,0.2,1] # 1 for inter\n",
    "base_optimizer=torch.optim.Adam\n",
    "loss_fn_clf=nn.CrossEntropyLoss()\n",
    "base_model_student='cnn_Ag'\n",
    "base_model_teacher='cnn_Ag_teacher_self_distill_leadI'\n",
    "class_num=3\n",
    "smote=True\n",
    "pair_num_per_anchor_batch=5\n",
    "CTL_margin=0.1\n",
    "warm_epoch=2\n",
    "total_epoch=30\n",
    "CRL_queue_len=5\n",
    "finetune_epoch=10\n",
    "# 计算两个模型标签的余弦相似度损失\n",
    "\n",
    "class CosineSimilarityLoss(torch.nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(CosineSimilarityLoss, self).__init__()  \n",
    "  \n",
    "    def forward(self, input1, input2):  \n",
    "        cos_sim = torch.mean(F.cosine_similarity(input1, input2))\n",
    "        loss = 1 - cos_sim  \n",
    "        return loss\n",
    "\n",
    "loss_fn_tslb = CosineSimilarityLoss()\n",
    "\n",
    "# 基于欧氏距离的特征对比损失 \n",
    "\n",
    "# 没有温度系数没考虑，因为relu已经考虑了平滑的效果。\n",
    "\n",
    "# 如果想用温度系数建议去问大模型。\n",
    "  \n",
    "class ContrastiveLoss(torch.nn.Module):  \n",
    "    def __init__(self, margin=1.):  \n",
    "        super(ContrastiveLoss, self).__init__()  \n",
    "        self.margin = torch.tensor(margin, dtype=torch.float32)\n",
    "  \n",
    "    def forward(self, anchor, positive, negative):  \n",
    "#         print('anchor:',anchor)\n",
    "#         print('positive:',positive)\n",
    "#         print('negative:',negative)\n",
    "        # 计算锚点和正样本之间的余弦相似度  \n",
    "        similarity_anchor_positive = F.cosine_similarity(anchor, positive, dim=-1)  \n",
    "#         print('positive:',similarity_anchor_positive)\n",
    "        # 计算锚点和负样本之间的余弦相似度  \n",
    "        similarity_anchor_negative = F.cosine_similarity(anchor, negative, dim=-1)  \n",
    "#         print('negtive:',similarity_anchor_negative)\n",
    "  \n",
    "        # 计算损失  \n",
    "        loss = torch.mean(F.relu(similarity_anchor_positive-similarity_anchor_negative))\n",
    "#         print('cft_loss=',loss)\n",
    "        return loss\n",
    "\n",
    "feature_contrastive_loss_fn = ContrastiveLoss(margin=CTL_margin)\n",
    "\n",
    "# 维护教师的特征内存队列和标签队列\n",
    "\n",
    "class TeacherQueue:  \n",
    "    def __init__(self, max_size):  \n",
    "        self.max_size = max_size  \n",
    "        self.feat_queue = deque(maxlen=max_size)  \n",
    "        self.label_queue = deque(maxlen=max_size)  \n",
    "  \n",
    "    def enqueue(self, features,labels):  \n",
    "        \"\"\"  \n",
    "        将特征向量加入队列  \n",
    "        :param features: 特征向量，形状为[batch_size, feature_dim]  \n",
    "        \"\"\"  \n",
    "        if len(self.feat_queue) == self.max_size:  \n",
    "            self.dequeue()  # 如果队列已满，先出队  \n",
    "        self.feat_queue.append(features)  \n",
    "        self.label_queue.append(labels)  \n",
    "  \n",
    "    def dequeue(self):  \n",
    "        \"\"\"  \n",
    "        从队列中移除最早加入的特征向量，无需返回值。  \n",
    "        \"\"\"  \n",
    "        self.feat_queue.popleft()  \n",
    "        self.label_queue.popleft()  \n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def get_queue_len(self):\n",
    "        return len(self.feat_queue)\n",
    "  \n",
    "    def get_all_queue(self):  \n",
    "        \"\"\"  \n",
    "        返回队列中所有的特征向量和标签，形状为[total_size, feature_dim],[total_size, label_dim]  \n",
    "        \"\"\"  \n",
    "        return torch.cat(list(self.feat_queue)),torch.cat(list(self.label_queue))\n",
    "\n",
    "def get_class_f1(tar,pred):\n",
    "    # 多分类多标签或单标签，输入为概率或one hot\n",
    "    pred_idx = pred.argmax(axis=1)\n",
    "    pred_=(pred_idx[:,None] == np.arange(pred.shape[1])).astype(int)\n",
    "    F1_normal_score,F1_AF_score,F1_other_score=list(sklearn.metrics.f1_score(tar, pred_, average=None))\n",
    "    return F1_normal_score,F1_AF_score,F1_other_score\n",
    "\n",
    "\n",
    "def test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                          test_datasloader, device):\n",
    "    \n",
    "    student_model.eval() \n",
    "    running_loss = None \n",
    "    test_pred=0\n",
    "    running_loss = []\n",
    "    test_tar=0\n",
    "    for step, (in_data_, targets_) in (enumerate(test_datasloader)):\n",
    "        tmp_data=np.zeros((in_data_.shape[0],1000,2))\n",
    "        tmp_data[:,:,0]=in_data_[:,:,0]\n",
    "        tmp_data[:,:-1,1]=in_data_[:,1:,0]-in_data_[:,0:-1,0]\n",
    "        preds_,_,_=student_model(torch.tensor(tmp_data).float().to(device))\n",
    "        preds_=preds_.float()\n",
    "        targets_for_loss=torch.max(targets_[:,:class_num],1).indices.long().to(device)\n",
    "        loss=loss_fn_clf(preds_,targets_for_loss)    \n",
    "        running_loss.append(loss.item())\n",
    "        mean_loss=np.mean(running_loss)\n",
    "\n",
    "        # 使用AUC作为评价指标\n",
    "        if type(test_pred)==int:\n",
    "            test_pred=preds_.clone().detach().cpu().numpy()\n",
    "        else:\n",
    "            test_pred=np.concatenate((test_pred,\n",
    "                                preds_.clone().detach().cpu().numpy(),\n",
    "                                ),axis=0)\n",
    "        if type(test_tar)==int:\n",
    "            test_tar=targets_.clone().detach().cpu().numpy()\n",
    "        else:\n",
    "            test_tar=np.concatenate((test_tar,\n",
    "                                targets_.clone().detach().cpu().numpy(),\n",
    "                                ),axis=0)\n",
    "\n",
    "    print('epoch=',epoch,)\n",
    "    print(\"test_loss=\",mean_loss)\n",
    "    print(\"________________________________\")\n",
    "    mean_macro_auc=sklearn.metrics.roc_auc_score(test_tar, test_pred, average='macro')\n",
    "#     print('test mean_macro_auc= ',mean_macro_auc)\n",
    "    \n",
    "#     print(test_tar.shape)\n",
    "#     print(test_pred.shape)\n",
    "    \n",
    "    F1_score=get_macro_f1(test_tar,test_pred)\n",
    "#     print('test F1_score= ',F1_score)\n",
    "    \n",
    "    precision=get_macro_precision(test_tar,test_pred)\n",
    "#     print('test precision= ',precision)\n",
    "    \n",
    "    recall=get_macro_recall(test_tar,test_pred)\n",
    "#     print('test recall= ',recall)\n",
    "\n",
    "    acc=get_acc(test_tar,test_pred)\n",
    "#     print('test acc= ',acc)\n",
    "    \n",
    "    F1_normal_score,F1_AF_score,F1_other_score=get_class_f1(test_tar, test_pred)\n",
    "    return str(int(round(1000*mean_macro_auc))),str(int(round(1000*precision))),str(int(round(1000*recall))),str(int(round(1000*F1_score))),str(int(round(1000*F1_normal_score))),str(int(round(1000*F1_AF_score))),str(int(round(1000*F1_other_score))),str(int(round(1000*acc)))\n",
    "\n",
    "tem_relu=nn.ReLU(inplace=False)\n",
    "\n",
    "# 定义训练流程\n",
    "def finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "                            max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "                            feature_contrastive_loss_fn, \\\n",
    "                            Teacher_queue,base_optimizer, \\\n",
    "                            train_datasloader,device):\n",
    "    student_model.train()\n",
    "    running_loss = None \n",
    "    # 维护一个对比损失的内存队列\n",
    "    for step, (in_data_, targets_) in (enumerate(tqdm(train_datasloader))):\n",
    "        # 教师模型的预测\n",
    "        \n",
    "        assert (gan_aug==3) # 进行一次教师模型的前向传播和队列存储，一次原有单导联蒸馏，3次单导联生成蒸馏\n",
    "        \n",
    "        current_iter=step+epoch*len(train_datasloader)\n",
    "        warm_iter=warm_epoch*len(train_datasloader)\n",
    "        total_iter=total_epoch*len(train_datasloader)\n",
    "        adjust_learning_rate(optimizer,current_iter,warm_iter,total_iter,max_lr,min_lr)\n",
    "        \n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             in_data_1 = in_data_[:,:,:1].float().to(device).clone()\n",
    "#             in_data_2 = GAN_model.generate_images(torch.cat((in_data_1,in_data_1,in_data_1),dim=0))  # 32,\n",
    "\n",
    "#             in_data_GAN4=torch.cat((in_data_1,in_data_2),dim=0)\n",
    "                                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        tmp_data=np.zeros((in_data_.shape[0],1000,2))\n",
    "        tmp_data[:,:,0]=in_data_[:,:,0]\n",
    "        tmp_data[:,:-1,1]=in_data_[:,1:,0]-in_data_[:,0:-1,0]\n",
    "        student_diag_preds_,student_domain_preds_,student_feature=student_model(torch.tensor(tmp_data).float().to(device))\n",
    "        student_diag_preds_=student_diag_preds_.float()\n",
    "\n",
    "        # 损失函数的计算和反向传播\n",
    "        # 分类损失部分\n",
    "        targets_for_diag_loss=torch.max(targets_[:,:class_num],1).indices.long().to(device)  # 这里的2是指两类。\n",
    "        loss_diag=loss_fn_clf(student_diag_preds_,targets_for_diag_loss)\n",
    "        loss=loss_diag\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if running_loss is None:\n",
    "            running_loss = loss.item() # 只输出重构损失\n",
    "        else:\n",
    "            running_loss = running_loss * .9 + loss.item() * .1   \n",
    "\n",
    "#             print('epoch=',epoch,)\n",
    "    print(\"train_running_loss=\",running_loss)\n",
    "\n",
    "            # loss的打印\n",
    "            \n",
    "    # 特征对比损失部分    \n",
    "    # 分类结果差异损失部分\n",
    "    # domain损失部分\n",
    "    # 分类损失部分\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb22bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data T_3cls\n",
      "test data size : 8249\n",
      "test label class :  [5076.  758. 2415.]\n",
      "total test data shape =  (8249, 1000, 1)\n",
      "total test label shape =  (8249, 3)\n",
      "total test data class =  [5076.  758. 2415.]\n",
      "test data R_3cls\n",
      "test data size : 4479\n",
      "test label class :  [3548.   76.  856.]\n",
      "total test data shape =  (4479, 1000, 1)\n",
      "total test label shape =  (4479, 3)\n",
      "total test data class =  [3548.   76.  856.]\n",
      "base_model=cnn_Ag\n",
      "ok\n",
      "epoch= 0\n",
      "test_loss= 0.9485348949065575\n",
      "________________________________\n",
      "793 633 673 627 636 743 503 594\n",
      "epoch= 0\n",
      "test_loss= 0.7349713018962315\n",
      "________________________________\n",
      "781 572 636 587 782 560 420 681\n"
     ]
    }
   ],
   "source": [
    "# 不finetune\n",
    "# 加载数据\n",
    "\n",
    "finetune_ratio=0\n",
    "\n",
    "\n",
    "test_T_data_list=['T_3cls']\n",
    "test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "test_R_data_list=['R_3cls']\n",
    "test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 更改加载的教师模型字典：\n",
    "# 开始训练流程\n",
    "student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# 现在，模型已经有了之前保存的参数\n",
    "teacher_model=None\n",
    "Teacher_queue=None\n",
    "\n",
    "print('ok')\n",
    "optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "    \n",
    "                                         \n",
    "T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(0,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_T_datasloader, device)\n",
    "print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(0,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_R_datasloader, device)\n",
    "print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 写入csv\n",
    "\n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'T',\n",
    "        T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "# with open('log/dist_GAN_ABCHLN_T_finetune_005_600000_20240301_total_AF_f1_box1.csv','a',encoding='utf-8')as file_obj:\n",
    "#     writer=csv.writer(file_obj)\n",
    "#     writer.writerow(header)\n",
    "#     for result in results:\n",
    "#         writer.writerow(result)\n",
    "        \n",
    "        \n",
    "# header=[\n",
    "#         'train\\\\test\\t',\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "# #         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "#         # round\n",
    "\n",
    "# results=[\n",
    "#         [\n",
    "#         'R',\n",
    "#         R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "#          ],\n",
    "#         ]\n",
    "\n",
    "# with open('log/dist_GAN_ABCHLN_R_finetune_600000_20240303_total_AF_f1_correct_save_exp1_box1.csv','a',encoding='utf-8')as file_obj:\n",
    "#     writer=csv.writer(file_obj)\n",
    "#     writer.writerow(header)\n",
    "#     for result in results:\n",
    "#         writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0798fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data T_3cls\n",
      "-\n",
      "(412, 1000, 1)\n",
      "(412,)\n",
      "smoted train data size : 783\n",
      "smoted train label class :  [261. 261. 261.]\n",
      "train data size : 783\n",
      "train label class :  [261. 261. 261. 783.]\n",
      "total train data shape =  (783, 1000, 1)\n",
      "total train label shape =  (783, 4)\n",
      "total train data class =  [261. 261. 261. 783.]\n",
      "train data R_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "(223, 1000, 1)\n",
      "(223,)\n",
      "smoted train data size : 516\n",
      "smoted train label class :  [172. 172. 172.]\n",
      "train data size : 516\n",
      "train label class :  [172. 172. 172. 516.]\n",
      "total train data shape =  (516, 1000, 1)\n",
      "total train label shape =  (516, 4)\n",
      "total train data class =  [172. 172. 172. 516.]\n",
      "test data T_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size : 7837\n",
      "test label class :  [4815.  721. 2301.]\n",
      "total test data shape =  (7837, 1000, 1)\n",
      "total test label shape =  (7837, 3)\n",
      "total test data class =  [4815.  721. 2301.]\n",
      "test data R_3cls\n",
      "test data size : 4256\n",
      "test label class :  [3376.   72.  809.]\n",
      "total test data shape =  (4256, 1000, 1)\n",
      "total test label shape =  (4256, 3)\n",
      "total test data class =  [3376.   72.  809.]\n",
      "base_model=cnn_Ag\n",
      "ok\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 1.6588309526921514\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 1.309098408875108\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.9393361127501727\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.6656334457337858\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.4714086024093331\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.42545211907809977\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3221599374823571\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3077299202825427\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.2821794821876884\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.2142082584000528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 9\n",
      "test_loss= 0.6785159606126047\n",
      "________________________________\n",
      "858 760 682 713 856 678 605 774\n",
      "epoch= 9\n",
      "test_loss= 0.6322946355623358\n",
      "________________________________\n",
      "757 624 544 575 872 471 384 782\n"
     ]
    }
   ],
   "source": [
    "# finetune=0.05\n",
    "# 加载数据\n",
    "\n",
    "finetune_ratio=0.05\n",
    "\n",
    "train_T_finetune_datasloader_instance=train_loader(dataname=['T_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_T_finetune_datasloader=train_T_finetune_datasloader_instance.loader()\n",
    "train_R_finetune_datasloader_instance=train_loader(dataname=['R_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_R_finetune_datasloader=train_R_finetune_datasloader_instance.loader()\n",
    " \n",
    "\n",
    "\n",
    "test_T_data_list=['T_3cls']\n",
    "test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "test_R_data_list=['R_3cls']\n",
    "test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 更改加载的教师模型字典：\n",
    "# 开始训练流程\n",
    "student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# 现在，模型已经有了之前保存的参数\n",
    "teacher_model=None\n",
    "Teacher_queue=None\n",
    "\n",
    "print('ok')\n",
    "optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(finetune_epoch):\n",
    "    print('_____________________________________')\n",
    "    print(' ')\n",
    "    time.sleep(0.1)\n",
    "    finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "                            max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "                            feature_contrastive_loss_fn, \\\n",
    "                            Teacher_queue,base_optimizer, \\\n",
    "                            train_T_finetune_datasloader,device)\n",
    "    \n",
    "                                         \n",
    "T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_T_datasloader, device)\n",
    "print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_R_datasloader, device)\n",
    "print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 写入csv\n",
    "\n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'T'+str(finetune_ratio),\n",
    "        T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "        \n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'R'+str(finetune_ratio),\n",
    "        R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37e39f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data T_3cls\n",
      "-\n",
      "(824, 1000, 1)\n",
      "(824,)\n",
      "smoted train data size : 1527\n",
      "smoted train label class :  [509. 509. 509.]\n",
      "train data size : 1527\n",
      "train label class :  [ 509.  509.  509. 1527.]\n",
      "total train data shape =  (1527, 1000, 1)\n",
      "total train label shape =  (1527, 4)\n",
      "total train data class =  [ 509.  509.  509. 1527.]\n",
      "train data R_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "(447, 1000, 1)\n",
      "(447,)\n",
      "smoted train data size : 1029\n",
      "smoted train label class :  [343. 343. 343.]\n",
      "train data size : 1029\n",
      "train label class :  [ 343.  343.  343. 1029.]\n",
      "total train data shape =  (1029, 1000, 1)\n",
      "total train label shape =  (1029, 4)\n",
      "total train data class =  [ 343.  343.  343. 1029.]\n",
      "test data T_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size : 7425\n",
      "test label class :  [4567.  676. 2182.]\n",
      "total test data shape =  (7425, 1000, 1)\n",
      "total test label shape =  (7425, 3)\n",
      "total test data class =  [4567.  676. 2182.]\n",
      "test data R_3cls\n",
      "test data size : 4032\n",
      "test label class :  [3205.   71.  757.]\n",
      "total test data shape =  (4032, 1000, 1)\n",
      "total test label shape =  (4032, 3)\n",
      "total test data class =  [3205.   71.  757.]\n",
      "base_model=cnn_Ag\n",
      "ok\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 1.3538579918031972\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 1.0909590121229724\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:01<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.6884520471093052\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.4775048376253714\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3843899716908263\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3352739997577771\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.2662470218143558\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.215744217314413\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.18577330615288698\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.18381027576069314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 9\n",
      "test_loss= 0.5966125049833524\n",
      "________________________________\n",
      "872 769 723 742 862 743 621 787\n",
      "epoch= 9\n",
      "test_loss= 0.637805949896574\n",
      "________________________________\n",
      "742 627 553 581 883 484 377 797\n"
     ]
    }
   ],
   "source": [
    "# finetune=0.1\n",
    "# 加载数据\n",
    "\n",
    "finetune_ratio=0.1\n",
    "\n",
    "train_T_finetune_datasloader_instance=train_loader(dataname=['T_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_T_finetune_datasloader=train_T_finetune_datasloader_instance.loader()\n",
    "train_R_finetune_datasloader_instance=train_loader(dataname=['R_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_R_finetune_datasloader=train_R_finetune_datasloader_instance.loader()\n",
    " \n",
    "\n",
    "\n",
    "test_T_data_list=['T_3cls']\n",
    "test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "test_R_data_list=['R_3cls']\n",
    "test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 更改加载的教师模型字典：\n",
    "# 开始训练流程\n",
    "student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# 现在，模型已经有了之前保存的参数\n",
    "teacher_model=None\n",
    "Teacher_queue=None\n",
    "\n",
    "print('ok')\n",
    "optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(finetune_epoch):\n",
    "    print('_____________________________________')\n",
    "    print(' ')\n",
    "    time.sleep(0.1)\n",
    "    finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "                            max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "                            feature_contrastive_loss_fn, \\\n",
    "                            Teacher_queue,base_optimizer, \\\n",
    "                            train_T_finetune_datasloader,device)\n",
    "    \n",
    "                                         \n",
    "T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_T_datasloader, device)\n",
    "print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_R_datasloader, device)\n",
    "print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 写入csv\n",
    "\n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'T'+str(finetune_ratio),\n",
    "        T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "        \n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'R'+str(finetune_ratio),\n",
    "        R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf0137d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data T_3cls\n",
      "-\n",
      "(1649, 1000, 1)\n",
      "(1649,)\n",
      "smoted train data size : 2988\n",
      "smoted train label class :  [996. 996. 996.]\n",
      "train data size : 2988\n",
      "train label class :  [ 996.  996.  996. 2988.]\n",
      "total train data shape =  (2988, 1000, 1)\n",
      "total train label shape =  (2988, 4)\n",
      "total train data class =  [ 996.  996.  996. 2988.]\n",
      "train data R_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "(895, 1000, 1)\n",
      "(895,)\n",
      "smoted train data size : 2079\n",
      "smoted train label class :  [693. 693. 693.]\n",
      "train data size : 2079\n",
      "train label class :  [ 693.  693.  693. 2079.]\n",
      "total train data shape =  (2079, 1000, 1)\n",
      "total train label shape =  (2079, 4)\n",
      "total train data class =  [ 693.  693.  693. 2079.]\n",
      "test data T_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size : 6600\n",
      "test label class :  [4080.  585. 1935.]\n",
      "total test data shape =  (6600, 1000, 1)\n",
      "total test label shape =  (6600, 3)\n",
      "total test data class =  [4080.  585. 1935.]\n",
      "test data R_3cls\n",
      "test data size : 3584\n",
      "test label class :  [2855.   62.  668.]\n",
      "total test data shape =  (3584, 1000, 1)\n",
      "total test label shape =  (3584, 3)\n",
      "total test data class =  [2855.   62.  668.]\n",
      "base_model=cnn_Ag\n",
      "ok\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 1.287852700858907\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.7045641893293739\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.46315211835913284\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3809043618760034\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.32984916646324525\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.30486159830148\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.28491115568557696\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.2565999979844622\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.23278360170893253\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.18251166137867275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 9\n",
      "test_loss= 0.5851485505700111\n",
      "________________________________\n",
      "881 759 746 751 863 753 638 791\n",
      "epoch= 9\n",
      "test_loss= 0.6189992438469615\n",
      "________________________________\n",
      "789 653 594 618 882 584 389 797\n"
     ]
    }
   ],
   "source": [
    "# finetune=0.2\n",
    "# 加载数据\n",
    "\n",
    "finetune_ratio=0.2\n",
    "\n",
    "train_T_finetune_datasloader_instance=train_loader(dataname=['T_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_T_finetune_datasloader=train_T_finetune_datasloader_instance.loader()\n",
    "train_R_finetune_datasloader_instance=train_loader(dataname=['R_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_R_finetune_datasloader=train_R_finetune_datasloader_instance.loader()\n",
    " \n",
    "\n",
    "\n",
    "test_T_data_list=['T_3cls']\n",
    "test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "test_R_data_list=['R_3cls']\n",
    "test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 更改加载的教师模型字典：\n",
    "# 开始训练流程\n",
    "student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# 现在，模型已经有了之前保存的参数\n",
    "teacher_model=None\n",
    "Teacher_queue=None\n",
    "\n",
    "print('ok')\n",
    "optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(finetune_epoch):\n",
    "    print('_____________________________________')\n",
    "    print(' ')\n",
    "    time.sleep(0.1)\n",
    "    finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "                            max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "                            feature_contrastive_loss_fn, \\\n",
    "                            Teacher_queue,base_optimizer, \\\n",
    "                            train_T_finetune_datasloader,device)\n",
    "    \n",
    "                                         \n",
    "T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_T_datasloader, device)\n",
    "print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_R_datasloader, device)\n",
    "print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 写入csv\n",
    "\n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'T'+str(finetune_ratio),\n",
    "        T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "        \n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'R'+str(finetune_ratio),\n",
    "        R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf263f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data T_3cls\n",
      "-\n",
      "(2474, 1000, 1)\n",
      "(2474,)\n",
      "smoted train data size : 4551\n",
      "smoted train label class :  [1517. 1517. 1517.]\n",
      "train data size : 4551\n",
      "train label class :  [1517. 1517. 1517. 4551.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train data shape =  (4551, 1000, 1)\n",
      "total train label shape =  (4551, 4)\n",
      "total train data class =  [1517. 1517. 1517. 4551.]\n",
      "train data R_3cls\n",
      "-\n",
      "(1343, 1000, 1)\n",
      "(1343,)\n",
      "smoted train data size : 3165\n",
      "smoted train label class :  [1055. 1055. 1055.]\n",
      "train data size : 3165\n",
      "train label class :  [1055. 1055. 1055. 3165.]\n",
      "total train data shape =  (3165, 1000, 1)\n",
      "total train label shape =  (3165, 4)\n",
      "total train data class =  [1055. 1055. 1055. 3165.]\n",
      "test data T_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size : 5775\n",
      "test label class :  [3559.  498. 1718.]\n",
      "total test data shape =  (5775, 1000, 1)\n",
      "total test label shape =  (5775, 3)\n",
      "total test data class =  [3559.  498. 1718.]\n",
      "test data R_3cls\n",
      "test data size : 3136\n",
      "test label class :  [2493.   49.  595.]\n",
      "total test data shape =  (3136, 1000, 1)\n",
      "total test label shape =  (3136, 3)\n",
      "total test data class =  [2493.   49.  595.]\n",
      "base_model=cnn_Ag\n",
      "ok\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 1.1199487263003831\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.5339672307702622\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.4023383517635137\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3715722536048722\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 17.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.33317226506637604\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3095863290790192\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.26031665857669223\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.24572740606911192\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.2115262026362988\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:02<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.20812515468536918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 9\n",
      "test_loss= 0.5821209893278454\n",
      "________________________________\n",
      "881 779 752 763 873 763 652 804\n",
      "epoch= 9\n",
      "test_loss= 0.6412942862510681\n",
      "________________________________\n",
      "761 625 582 595 888 515 382 805\n"
     ]
    }
   ],
   "source": [
    "# finetune=0.3\n",
    "# 加载数据\n",
    "\n",
    "finetune_ratio=0.3\n",
    "\n",
    "train_T_finetune_datasloader_instance=train_loader(dataname=['T_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_T_finetune_datasloader=train_T_finetune_datasloader_instance.loader()\n",
    "train_R_finetune_datasloader_instance=train_loader(dataname=['R_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_R_finetune_datasloader=train_R_finetune_datasloader_instance.loader()\n",
    " \n",
    "\n",
    "\n",
    "test_T_data_list=['T_3cls']\n",
    "test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "test_R_data_list=['R_3cls']\n",
    "test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 更改加载的教师模型字典：\n",
    "# 开始训练流程\n",
    "student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# 现在，模型已经有了之前保存的参数\n",
    "teacher_model=None\n",
    "Teacher_queue=None\n",
    "\n",
    "print('ok')\n",
    "optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(finetune_epoch):\n",
    "    print('_____________________________________')\n",
    "    print(' ')\n",
    "    time.sleep(0.1)\n",
    "    finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "                            max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "                            feature_contrastive_loss_fn, \\\n",
    "                            Teacher_queue,base_optimizer, \\\n",
    "                            train_T_finetune_datasloader,device)\n",
    "    \n",
    "                                         \n",
    "T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_T_datasloader, device)\n",
    "print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_R_datasloader, device)\n",
    "print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 写入csv\n",
    "\n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'T'+str(finetune_ratio),\n",
    "        T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "        \n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'R'+str(finetune_ratio),\n",
    "        R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268be956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data T_3cls\n",
      "-\n",
      "(4124, 1000, 1)\n",
      "(4124,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoted train data size : 7716\n",
      "smoted train label class :  [2572. 2572. 2572.]\n",
      "train data size : 7716\n",
      "train label class :  [2572. 2572. 2572. 7716.]\n",
      "total train data shape =  (7716, 1000, 1)\n",
      "total train label shape =  (7716, 4)\n",
      "total train data class =  [2572. 2572. 2572. 7716.]\n",
      "train data R_3cls\n",
      "-\n",
      "(2239, 1000, 1)\n",
      "(2239,)\n",
      "smoted train data size : 5319\n",
      "smoted train label class :  [1773. 1773. 1773.]\n",
      "train data size : 5319\n",
      "train label class :  [1773. 1773. 1773. 5319.]\n",
      "total train data shape =  (5319, 1000, 1)\n",
      "total train label shape =  (5319, 4)\n",
      "total train data class =  [1773. 1773. 1773. 5319.]\n",
      "test data T_3cls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangli/software/miniconda3/envs/ecg_20230310/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size : 4125\n",
      "test label class :  [2504.  353. 1268.]\n",
      "total test data shape =  (4125, 1000, 1)\n",
      "total test label shape =  (4125, 3)\n",
      "total test data class =  [2504.  353. 1268.]\n",
      "test data R_3cls\n",
      "test data size : 2240\n",
      "test label class :  [1775.   43.  423.]\n",
      "total test data shape =  (2240, 1000, 1)\n",
      "total test label shape =  (2240, 3)\n",
      "total test data class =  [1775.   43.  423.]\n",
      "base_model=cnn_Ag\n",
      "ok\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.8598703630354833\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.4689636016019429\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3990794091821386\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3549011292570324\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.3332086412692472\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.28803875395494727\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.263608442833289\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 16.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.22380761567218113\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.21454747182190514\n",
      "_____________________________________\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:03<00:00, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_running_loss= 0.20359892995450474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 9\n",
      "test_loss= 0.6173498061570254\n",
      "________________________________\n",
      "873 773 734 751 854 758 641 785\n",
      "epoch= 9\n",
      "test_loss= 0.6386434584856033\n",
      "________________________________\n",
      "781 677 564 606 879 571 368 792\n"
     ]
    }
   ],
   "source": [
    "# finetune=0.5\n",
    "# 加载数据\n",
    "\n",
    "finetune_ratio=0.5\n",
    "\n",
    "train_T_finetune_datasloader_instance=train_loader(dataname=['T_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_T_finetune_datasloader=train_T_finetune_datasloader_instance.loader()\n",
    "train_R_finetune_datasloader_instance=train_loader(dataname=['R_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "train_R_finetune_datasloader=train_R_finetune_datasloader_instance.loader()\n",
    " \n",
    "\n",
    "\n",
    "test_T_data_list=['T_3cls']\n",
    "test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "test_R_data_list=['R_3cls']\n",
    "test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 更改加载的教师模型字典：\n",
    "# 开始训练流程\n",
    "student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# 现在，模型已经有了之前保存的参数\n",
    "teacher_model=None\n",
    "Teacher_queue=None\n",
    "\n",
    "print('ok')\n",
    "optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(finetune_epoch):\n",
    "    print('_____________________________________')\n",
    "    print(' ')\n",
    "    time.sleep(0.1)\n",
    "    finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "                            max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "                            feature_contrastive_loss_fn, \\\n",
    "                            Teacher_queue,base_optimizer, \\\n",
    "                            train_T_finetune_datasloader,device)\n",
    "    \n",
    "                                         \n",
    "T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_T_datasloader, device)\n",
    "print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "                      test_R_datasloader, device)\n",
    "print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 写入csv\n",
    "\n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'T'+str(finetune_ratio),\n",
    "        T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "        \n",
    "header=[\n",
    "        'train\\\\test\\t',\n",
    "        'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "        # round\n",
    "\n",
    "results=[\n",
    "        [\n",
    "        'R'+str(finetune_ratio),\n",
    "        R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "         ],\n",
    "        ]\n",
    "\n",
    "with open('log/proposed_600000_finetune_ABCHLN_TR_0308_smoteTrue.csv','a',encoding='utf-8')as file_obj:\n",
    "    writer=csv.writer(file_obj)\n",
    "    writer.writerow(header)\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181f0200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # finetune=0.8\n",
    "# # 加载数据\n",
    "\n",
    "# finetune_ratio=0.8\n",
    "\n",
    "# train_T_finetune_datasloader_instance=train_loader(dataname=['T_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "# train_T_finetune_datasloader=train_T_finetune_datasloader_instance.loader()\n",
    "# train_R_finetune_datasloader_instance=train_loader(dataname=['R_3cls'],train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,smote=smote,maple=False,class_num=class_num)\n",
    "# train_R_finetune_datasloader=train_R_finetune_datasloader_instance.loader()\n",
    " \n",
    "\n",
    "\n",
    "# test_T_data_list=['T_3cls']\n",
    "# test_T_datasloader=test_loader(dataname=test_T_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "# test_R_data_list=['R_3cls']\n",
    "# test_R_datasloader=test_loader(dataname=test_R_data_list,train_val_test_split=[finetune_ratio,0,1-finetune_ratio],bs=batch_size,num_workers=2,class_num=class_num).loader()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 更改加载的教师模型字典：\n",
    "# # 开始训练流程\n",
    "# student_model=generate_model(base_model=base_model_student,input_channels=2, num_classes=class_num,DG_method=DG_method_student,domain_classes=6,distill=distill).to(device)\n",
    "# student_model.load_state_dict(torch.load('save_model_states/1709996629_ABCLNH_TR_proposed_xuesheng_cnnAg_zong_f1.pth'))  \n",
    "  \n",
    "# # 现在，模型已经有了之前保存的参数\n",
    "# teacher_model=None\n",
    "# Teacher_queue=None\n",
    "\n",
    "# print('ok')\n",
    "# optimizer=generate_optimizer(base_optimizer=base_optimizer,model_parameters=student_model.parameters(),SAM_flag=False,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# for epoch in range(finetune_epoch):\n",
    "#     print('_____________________________________')\n",
    "#     print(' ')\n",
    "#     time.sleep(0.1)\n",
    "#     finetune_student_one_epoch(epoch,warm_epoch,total_epoch,student_model,teacher_model, \\\n",
    "#                             max_lr,min_lr,loss_fn_clf,loss_fn_tslb,optimizer, \\\n",
    "#                             feature_contrastive_loss_fn, \\\n",
    "#                             Teacher_queue,base_optimizer, \\\n",
    "#                             train_T_finetune_datasloader,device)\n",
    "    \n",
    "                                         \n",
    "# T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "#                       test_T_datasloader, device)\n",
    "# print(T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc)\n",
    "\n",
    "# R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc=test_student_one_epoch(epoch,warm_epoch, total_epoch, student_model,loss_fn_clf, \\\n",
    "#                       test_R_datasloader, device)\n",
    "# print(R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# # 写入csv\n",
    "\n",
    "# header=[\n",
    "#         'train\\\\test\\t',\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "# #         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "#         # round\n",
    "\n",
    "# results=[\n",
    "#         [\n",
    "#         'T'+str(finetune_ratio),\n",
    "#         T_auc,T_pre,T_rec,T_f1_test,T_f1_test_normal,T_f1_test_AF,T_f1_test_Other,T_acc+'\\t',\n",
    "#          ],\n",
    "#         ]\n",
    "\n",
    "# with open('log/proposed_600000_finetune_ABCHLN_TR_0308.csv','a',encoding='utf-8')as file_obj:\n",
    "#     writer=csv.writer(file_obj)\n",
    "#     writer.writerow(header)\n",
    "#     for result in results:\n",
    "#         writer.writerow(result)\n",
    "        \n",
    "        \n",
    "# header=[\n",
    "#         'train\\\\test\\t',\n",
    "#         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "# #         'auc','pre','rec','f1','normal-f1','AF-f1','other-f1','acc\\t',]\n",
    "\n",
    "#         # round\n",
    "\n",
    "# results=[\n",
    "#         [\n",
    "#         'R'+str(finetune_ratio),\n",
    "#         R_auc,R_pre,R_rec,R_f1_test,R_f1_test_normal,R_f1_test_AF,R_f1_test_Other,R_acc+'\\t',\n",
    "#          ],\n",
    "#         ]\n",
    "\n",
    "# with open('log/proposed_600000_finetune_ABCHLN_TR_0308.csv','a',encoding='utf-8')as file_obj:\n",
    "#     writer=csv.writer(file_obj)\n",
    "#     writer.writerow(header)\n",
    "#     for result in results:\n",
    "#         writer.writerow(result)\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775495cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SMOTE in module imblearn.over_sampling._smote.base:\n",
      "\n",
      "class SMOTE(BaseSMOTE)\n",
      " |  SMOTE(*, sampling_strategy='auto', random_state=None, k_neighbors=5, n_jobs=None)\n",
      " |  \n",
      " |  Class to perform over-sampling using SMOTE.\n",
      " |  \n",
      " |  This object is an implementation of SMOTE - Synthetic Minority\n",
      " |  Over-sampling Technique as presented in [1]_.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <smote_adasyn>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  sampling_strategy : float, str, dict or callable, default='auto'\n",
      " |      Sampling information to resample the data set.\n",
      " |  \n",
      " |      - When ``float``, it corresponds to the desired ratio of the number of\n",
      " |        samples in the minority class over the number of samples in the\n",
      " |        majority class after resampling. Therefore, the ratio is expressed as\n",
      " |        :math:`\\alpha_{os} = N_{rm} / N_{M}` where :math:`N_{rm}` is the\n",
      " |        number of samples in the minority class after resampling and\n",
      " |        :math:`N_{M}` is the number of samples in the majority class.\n",
      " |  \n",
      " |          .. warning::\n",
      " |             ``float`` is only available for **binary** classification. An\n",
      " |             error is raised for multi-class classification.\n",
      " |  \n",
      " |      - When ``str``, specify the class targeted by the resampling. The\n",
      " |        number of samples in the different classes will be equalized.\n",
      " |        Possible choices are:\n",
      " |  \n",
      " |          ``'minority'``: resample only the minority class;\n",
      " |  \n",
      " |          ``'not minority'``: resample all classes but the minority class;\n",
      " |  \n",
      " |          ``'not majority'``: resample all classes but the majority class;\n",
      " |  \n",
      " |          ``'all'``: resample all classes;\n",
      " |  \n",
      " |          ``'auto'``: equivalent to ``'not majority'``.\n",
      " |  \n",
      " |      - When ``dict``, the keys correspond to the targeted classes. The\n",
      " |        values correspond to the desired number of samples for each targeted\n",
      " |        class.\n",
      " |  \n",
      " |      - When callable, function taking ``y`` and returns a ``dict``. The keys\n",
      " |        correspond to the targeted classes. The values correspond to the\n",
      " |        desired number of samples for each class.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Control the randomization of the algorithm.\n",
      " |  \n",
      " |      - If int, ``random_state`` is the seed used by the random number\n",
      " |        generator;\n",
      " |      - If ``RandomState`` instance, random_state is the random number\n",
      " |        generator;\n",
      " |      - If ``None``, the random number generator is the ``RandomState``\n",
      " |        instance used by ``np.random``.\n",
      " |  \n",
      " |  k_neighbors : int or object, default=5\n",
      " |      The nearest neighbors used to define the neighborhood of samples to use\n",
      " |      to generate the synthetic samples. You can pass:\n",
      " |  \n",
      " |      - an `int` corresponding to the number of neighbors to use. A\n",
      " |        `~sklearn.neighbors.NearestNeighbors` instance will be fitted in this\n",
      " |        case.\n",
      " |      - an instance of a compatible nearest neighbors algorithm that should\n",
      " |        implement both methods `kneighbors` and `kneighbors_graph`. For\n",
      " |        instance, it could correspond to a\n",
      " |        :class:`~sklearn.neighbors.NearestNeighbors` but could be extended to\n",
      " |        any compatible class.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of CPU cores used during the cross-validation loop.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See\n",
      " |      `Glossary <https://scikit-learn.org/stable/glossary.html#term-n-jobs>`_\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. deprecated:: 0.10\n",
      " |         `n_jobs` has been deprecated in 0.10 and will be removed in 0.12.\n",
      " |         It was previously used to set `n_jobs` of nearest neighbors\n",
      " |         algorithm. From now on, you can pass an estimator where `n_jobs` is\n",
      " |         already set instead.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  sampling_strategy_ : dict\n",
      " |      Dictionary containing the information to sample the dataset. The keys\n",
      " |      corresponds to the class labels from which to sample and the values\n",
      " |      are the number of samples to sample.\n",
      " |  \n",
      " |  nn_k_ : estimator object\n",
      " |      Validated k-nearest neighbours created from the `k_neighbors` parameter.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features in the input dataset.\n",
      " |  \n",
      " |      .. versionadded:: 0.9\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during `fit`. Defined only when `X` has feature\n",
      " |      names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 0.10\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SMOTENC : Over-sample using SMOTE for continuous and categorical features.\n",
      " |  \n",
      " |  SMOTEN : Over-sample using the SMOTE variant specifically for categorical\n",
      " |      features only.\n",
      " |  \n",
      " |  BorderlineSMOTE : Over-sample using the borderline-SMOTE variant.\n",
      " |  \n",
      " |  SVMSMOTE : Over-sample using the SVM-SMOTE variant.\n",
      " |  \n",
      " |  ADASYN : Over-sample using ADASYN.\n",
      " |  \n",
      " |  KMeansSMOTE : Over-sample applying a clustering before to oversample using\n",
      " |      SMOTE.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See the original papers: [1]_ for more details.\n",
      " |  \n",
      " |  Supports multi-class resampling. A one-vs.-rest scheme is used as\n",
      " |  originally proposed in [1]_.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, \"SMOTE:\n",
      " |     synthetic minority over-sampling technique,\" Journal of artificial\n",
      " |     intelligence research, 321-357, 2002.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from collections import Counter\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from imblearn.over_sampling import SMOTE\n",
      " |  >>> X, y = make_classification(n_classes=2, class_sep=2,\n",
      " |  ... weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
      " |  ... n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
      " |  >>> print('Original dataset shape %s' % Counter(y))\n",
      " |  Original dataset shape Counter({1: 900, 0: 100})\n",
      " |  >>> sm = SMOTE(random_state=42)\n",
      " |  >>> X_res, y_res = sm.fit_resample(X, y)\n",
      " |  >>> print('Resampled dataset shape %s' % Counter(y_res))\n",
      " |  Resampled dataset shape Counter({0: 900, 1: 900})\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SMOTE\n",
      " |      BaseSMOTE\n",
      " |      imblearn.over_sampling.base.BaseOverSampler\n",
      " |      imblearn.base.BaseSampler\n",
      " |      imblearn.base.SamplerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.OneToOneFeatureMixin\n",
      " |      imblearn.base._ParamsValidationMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, sampling_strategy='auto', random_state=None, k_neighbors=5, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from imblearn.base.BaseSampler:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Check inputs and statistics of the sampler.\n",
      " |      \n",
      " |      You should use ``fit_resample`` in all cases.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, dataframe, sparse matrix} of shape                 (n_samples, n_features)\n",
      " |          Data array.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Return the instance itself.\n",
      " |  \n",
      " |  fit_resample(self, X, y)\n",
      " |      Resample the dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, dataframe, sparse matrix} of shape                 (n_samples, n_features)\n",
      " |          Matrix containing the data which have to be sampled.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Corresponding label for each sample in X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_resampled : {array-like, dataframe, sparse matrix} of shape                 (n_samples_new, n_features)\n",
      " |          The array containing the resampled data.\n",
      " |      \n",
      " |      y_resampled : array-like of shape (n_samples_new,)\n",
      " |          The corresponding label of `X_resampled`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Same as input features.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE  \n",
    "  \n",
    "help(SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa3677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b1fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bd894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4c463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2de4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd8bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954d515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d50cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c18a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3b1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
